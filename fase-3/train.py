# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nLA-MiXs_yh9aT9v59ttPb4klTIr4nnn
"""

#Se importan las librerías necesarias
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import LabelEncoder
from lightgbm import LGBMClassifier

#Se carga el archivo con los datos de entrenamiento (variables predictoras y la variable a predecir)
print("Charging train data...")
train = pd.read_csv('train_dataset.csv')

#Se convierte la variable customer_experience a valores numéricos ordenados
#0: bad, 1: neutral, 2: good
train['customer_experience'] = pd.Categorical(train['customer_experience'], categories=['bad', 'neutral', 'good'], ordered=True)
train['customer_experience'] = train['customer_experience'].cat.codes

#Se convierten las columnas de fecha al formato datetime
train['Date_Registered'] = pd.to_datetime(train['Date_Registered'])
train['payment_datetime'] = pd.to_datetime(train['payment_datetime'])
train['purchased_datetime'] = pd.to_datetime(train['purchased_datetime'])
train['released_date'] = pd.to_datetime(train['released_date'])
train['estimated_delivery_date'] = pd.to_datetime(train['estimated_delivery_date'])
train['received_date'] = pd.to_datetime(train['received_date'])

#Se extraen las características temporales y se generan variables derivadas de las fechas (hora, día, mes, etc.)
train['purchase_hour'] = train['payment_datetime'].dt.hour
train['purchase_day'] = train['payment_datetime'].dt.day_name()
train['purchase_month'] = train['payment_datetime'].dt.month
train['days_since_registration'] = (train['purchased_datetime'] - train['Date_Registered']).dt.days
train['estimated_delivery_day'] = train['estimated_delivery_date'].dt.day_name()
train['received_day'] = train['received_date'].dt.day_name()

#Se convierten las columnas de fecha a timestamp de Unix
date_columns = ['Date_Registered', 'payment_datetime', 'purchased_datetime',
                'released_date', 'estimated_delivery_date', 'received_date']

for col in date_columns:
    train[col] = pd.to_datetime(train[col], errors='coerce').astype(int) / 10**9

#Se convierten las variables categóricas a un formato númerico

categorical_columns = ['Gender', 'Is_current_loyalty_program_member',
                       'product_category',
                       'payment_method', 'purchase_medium', 'shipping_method', 'purchase_day','estimated_delivery_day','received_day']

label_encoder = LabelEncoder()

for col in categorical_columns:
    train[col] = label_encoder.fit_transform(train[col].astype(str))

#Se crean nuevas variables derivadas de las fechas y variables económicas
train['Delivery_time'] = train['received_date'] - train['released_date']
train['Delivery_delay'] = train['received_date'] - train['estimated_delivery_date']
train['Waiting_time'] = train['received_date'] - train['payment_datetime']
train['Additional_charge'] = train['final_payment'] - train['Product_value']
train['Waiting_percentage'] = (train['received_date'] - train['estimated_delivery_date'])/(train['received_date'] - train['payment_datetime'])
train['Processing_time'] = train['released_date'] - train['payment_datetime']
train['Loyalty_engagement'] = train['loyalty_points_redeemed'] / train['Product_value']

#Convierte los valores no numéricos a valores nulos

train.replace(r'[^0-9]+', np.nan, regex=True, inplace=True)

#Cambia los valores faltantes por el número 0
train.fillna(0, inplace=True)

#Se convierte todo el Data Frame a tipo numérico
train = train.apply(pd.to_numeric)

#Se separan las variables predictoras y la variable objetivo
#X: variables independientes (todas las columnas excepto 'customer_experience')
#y: variable dependiente u objetivo ('customer_experience'), es la que se va a predecir
X = train.drop(['customer_experience','tracking_number', 'user_id', 'loyalty_tier','purchase_medium' ,'shipping_method','Gender','order_id', 'Received_tier_discount_percentage','Is_current_loyalty_program_member', 'transaction_id'],axis=1)
y = train['customer_experience']

#Se configura el modelo LGBMC Classifier

print("Training model...")
model = LGBMClassifier(
    n_estimators=100,
    max_depth=9,
    learning_rate=0.1,
    num_leaves=57,
    feature_fraction=0.7233,
    bagging_fraction=0.7492,
    lambda_l1=1.9796,
    lambda_l2=8.1072,
    random_state=42
)

#Se entrena el modelo de LGBM con los datos de prueba
model.fit(X, y)

#Se usa joblib para guardar el modelo LGBM entrenado en el archivo model.pkl
joblib.dump(model, 'model.pkl')
print("Model trained and saved in model.pkl")